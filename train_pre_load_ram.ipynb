{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e920858-68f3-4cb1-b8c1-b32293cd5882",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/torch/utils/data/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# TODO(VitalyFedyunin): Rearranging this imports leads to crash,\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# need to cleanup dependencies and fix it\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msampler\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     BatchSampler,\n\u001b[1;32m      5\u001b[0m     RandomSampler,\n\u001b[1;32m      6\u001b[0m     Sampler,\n\u001b[1;32m      7\u001b[0m     SequentialSampler,\n\u001b[1;32m      8\u001b[0m     SubsetRandomSampler,\n\u001b[1;32m      9\u001b[0m     WeightedRandomSampler,\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     12\u001b[0m     ChainDataset,\n\u001b[1;32m     13\u001b[0m     ConcatDataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     random_split,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatapipes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatapipe\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     21\u001b[0m     DFIterDataPipe,\n\u001b[1;32m     22\u001b[0m     DataChunk,\n\u001b[1;32m     23\u001b[0m     IterDataPipe,\n\u001b[1;32m     24\u001b[0m     MapDataPipe,\n\u001b[1;32m     25\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/torch/utils/data/sampler.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m Tensor\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Iterator, Iterable, Optional, Sequence, List, TypeVar, Generic, Sized, Union\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/torch/__init__.py:249\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(textwrap\u001b[39m.\u001b[39mdedent(\u001b[39m'''\u001b[39m\n\u001b[1;32m    236\u001b[0m \u001b[39m            Failed to load PyTorch C extensions:\u001b[39m\n\u001b[1;32m    237\u001b[0m \u001b[39m                It appears that PyTorch has loaded the `torch/_C` folder\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[39m                or by running Python from a different directory.\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39m            \u001b[39m\u001b[39m'''\u001b[39m)\u001b[39m.\u001b[39mstrip()) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    247\u001b[0m     \u001b[39mraise\u001b[39;00m  \u001b[39m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mdir\u001b[39m(_C):\n\u001b[1;32m    250\u001b[0m     \u001b[39mif\u001b[39;00m name[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m name\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39mBase\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    251\u001b[0m         __all__\u001b[39m.\u001b[39mappend(name)\n",
      "\u001b[0;31mNameError\u001b[0m: name '_C' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import re\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision.models import *\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "839bfed5-46ca-4488-a914-fd0083398c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgDir = '/export/hdd/scratch/dataset/imagenet/train/n01694178'\n",
    "test_imgDir = './cifar_10_images/test_cifar10'\n",
    "batch_size = 128\n",
    "batch_size_test  = 100\n",
    "train_nSamples = 50000\n",
    "test_nSamples = 10000\n",
    "init_width = 32\n",
    "init_height = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ec9fd1f2-8164-4c3f-98b1-8376054057eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "41cac003-fb0f-497b-838b-4689dac77e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_path(imgDir):\n",
    "\n",
    "    all_training_files=os.walk(imgDir)\n",
    "    train_files=[]\n",
    "    train_imageNames=[]\n",
    "    train_nSamples=0\n",
    "    for path,direction,filelist in all_training_files:\n",
    "        files = [file for file in filelist if os.path.isfile(os.path.join(path, file))]\n",
    "        imageNames = [file.split('.')[0] for file in files if is_image_file(file)]\n",
    "        files = [os.path.join(path, file) for file in files if is_image_file(file)]\n",
    "        train_files.append(files)\n",
    "        train_imageNames.append(imageNames)\n",
    "        train_nSamples=train_nSamples+len(files)\n",
    "    train_files=sum(train_files,[])\n",
    "    train_imageNames=sum(train_imageNames,[])\n",
    "    #print(train_imageNames)\n",
    "    train_imageNames.sort(key = lambda i:int(re.match(r'(\\d+)',i).group()))\n",
    "    #train_imageNames.sort(key = lambda x: int(x[:-4]))\n",
    "    train_image_path = []\n",
    "    for i in range (len(train_imageNames)):\n",
    "        string = imgDir + '/' + train_imageNames[i] + '.jpg'\n",
    "        train_image_path.append(string)\n",
    "    return train_image_path\n",
    "\n",
    "def load_image_path_test(imgDir):\n",
    "\n",
    "    all_training_files=os.walk(imgDir)\n",
    "    train_files=[]\n",
    "    train_imageNames=[]\n",
    "    train_nSamples=0\n",
    "    for path,direction,filelist in all_training_files:\n",
    "        files = [file for file in filelist if os.path.isfile(os.path.join(path, file))]\n",
    "        imageNames = [file.split('.')[0] for file in files if is_image_file(file)]\n",
    "        files = [os.path.join(path, file) for file in files if is_image_file(file)]\n",
    "        train_files.append(files)\n",
    "        train_imageNames.append(imageNames)\n",
    "        train_nSamples=train_nSamples+len(files)\n",
    "    train_files=sum(train_files,[])\n",
    "    train_imageNames=sum(train_imageNames,[])\n",
    "    #print(train_imageNames)\n",
    "    train_imageNames.sort(key = lambda i:int(re.match(r'(\\d+)',i).group()))\n",
    "    #train_imageNames.sort(key = lambda x: int(x[:-4]))\n",
    "    train_image_path = []\n",
    "    for i in range (len(train_imageNames)):\n",
    "        string = imgDir + '/' + train_imageNames[i] + '.jpg'\n",
    "        train_image_path.append(string)\n",
    "    return train_image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7ce1f08c-2584-405a-8589-ad6b02806bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_path = load_image_path(imgDir)\n",
    "test_image_path = load_image_path_test(test_imgDir)\n",
    "train_label = np.load(\"cifar_10_labels.npy\")\n",
    "test_label = np.load(\"cifar_10_labels_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3a45b563-2583-4493-b658-b3e542199b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class listDataset_RAM(Dataset):\n",
    "    def __init__(self,data, target, nsamples,shape=None, shuffle=True, transform=None, target_transform=None, train=False, seen=0, batch_size=32, num_workers=0):\n",
    "      \n",
    "      self.data=data\n",
    "      self.target=target\n",
    "      self.nSamples=nsamples\n",
    "      self.transform = transform\n",
    "      self.target_transform = target_transform\n",
    "      self.train = train\n",
    "      self.shape = shape\n",
    "      self.seen = seen\n",
    "      self.batch_size = batch_size\n",
    "      self.num_workers = num_workers\n",
    "       \n",
    "    def __len__(self):\n",
    "        return self.nSamples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #imgpath = self.image_root[index]\n",
    "        #img = Image.open(imgpath).convert('RGB')\n",
    "     #print(img)\n",
    "        img = self.data[index]\n",
    "        if self.shape is not None:\n",
    "            img = img.resize(self.shape)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        label=self.target[index]\n",
    "        #print(label.type)\n",
    "        label = torch.from_numpy(np.array(label, dtype = np.int64))\n",
    "     \n",
    "        return (img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b47a2c94-dd20-4ac9-9115-eb733c7dc4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2bd82b51-ab63-44a0-86df-4e299779cc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n"
     ]
    }
   ],
   "source": [
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    #transforms.ToPILImage(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ef910281-e276-40f8-aeab-e2d4c93340fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = np.zeros([len(train_image_path), 3 ,32,32])\n",
    "#test_data = np.zeros([len(test_image_path), 3 ,32,32])                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "eb8fc776-5265-4c45-aab1-7769b4142bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./cifar_10_images/train_cifar10/4.jpg\n"
     ]
    }
   ],
   "source": [
    "#print(test_data.shape)\n",
    "print(train_image_path[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9d6984b4-3bb6-4127-bff7-16ef6b58565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range (len(train_data)):\n",
    "#     img = cv2.imread(train_image_path[i])\n",
    "#     #print(img.shape)\n",
    "#     #img = np.tranpose(\n",
    "#     img = np.transpose(img,(2,0,1))\n",
    "#     #print(img.shape)\n",
    "#     train_data[i] = np.array(img, dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ec08bbac-c311-417a-8a96-ac4f936d8a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range (len(test_data)):\n",
    "#     img = cv2.imread(test_image_path[i])\n",
    "#     #print(img.shape)\n",
    "#     #img = np.tranpose(\n",
    "#     img = np.transpose(img,(2,0,1))\n",
    "#     #print(img.shape)\n",
    "#     test_data[i] = np.array(img, dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0e443bd5-7fe3-49f9-a2c2-bfd87bb21024",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "for i in range (len(train_image_path)):\n",
    "    img = Image.open(train_image_path[i]).convert('RGB')\n",
    "    train_data.append(img)\n",
    "    \n",
    "for i in range (len(test_image_path)):\n",
    "    img = Image.open(test_image_path[i]).convert('RGB')\n",
    "    test_data.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a05c3f2e-5997-49ff-8c58-d380ca3e4763",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_label_tensor=torch.from_numpy(train_label.astype(np.int64))\n",
    "#test_label_tensor=torch.from_numpy(test_label.astype(np.int64))\n",
    "#image_tensor=torch.from_numpy(train_data.astype(np.float32))\n",
    "#image_test_tensor = torch.from_numpy(test_data.astype(np.float32))\n",
    "#train_data=Data.TensorDataset(image_tensor,train_label_tensor)\n",
    "#test_data=Data.TensorDataset(image_test_tensor,test_label_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b98db275-12d8-4b9b-98ce-a0e2bc92ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        listDataset_RAM(train_data, train_label, train_nSamples, shape=(init_width, init_height),\n",
    "                       shuffle=False,\n",
    "                       transform=transform_train, \n",
    "                       train=True, \n",
    "                       seen=0,\n",
    "                       batch_size=batch_size,\n",
    "                       num_workers=0),\n",
    "        batch_size=batch_size, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b5a4fb32-f7e0-4e6c-a52e-e2af44956e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "        listDataset_RAM(test_data, test_label, test_nSamples, shape=(init_width, init_height),\n",
    "                       shuffle=False,\n",
    "                       transform=transform_test, \n",
    "                       train=False, \n",
    "                       seen=0,\n",
    "                       batch_size=batch_size,\n",
    "                       num_workers=0),\n",
    "        batch_size=batch_size_test, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "78e85829-dc31-44ad-8a45-e36e6d5ff6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet18()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ebb3b758-ef20-4fa2-930a-f759fafe5cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Loss: 0.01157184 | Acc: 46.02200000% (23011/50000)\n",
      "Loss: 0.01110253 | Acc: 60.76000000% (6076/10000)\n",
      "Saving..\n",
      "the time for one epoch is: 30.619449138641357\n",
      "\n",
      "Epoch: 1\n",
      "Loss: 0.00771822 | Acc: 64.97800000% (32489/50000)\n",
      "Loss: 0.01085528 | Acc: 64.02000000% (6402/10000)\n",
      "Saving..\n",
      "the time for one epoch is: 30.908252716064453\n",
      "\n",
      "Epoch: 2\n",
      "Loss: 0.00596821 | Acc: 73.35200000% (36676/50000)\n",
      "Loss: 0.00795556 | Acc: 72.99000000% (7299/10000)\n",
      "Saving..\n",
      "the time for one epoch is: 30.215903997421265\n",
      "\n",
      "Epoch: 3\n",
      "Loss: 0.00503037 | Acc: 77.74000000% (38870/50000)\n",
      "Loss: 0.00601846 | Acc: 79.87000000% (7987/10000)\n",
      "Saving..\n",
      "the time for one epoch is: 26.67912983894348\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_156361/574327667.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m#lr = adjust_learning_rate(epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_156361/574327667.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/export/hdd/scratch/hchen799/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/export/hdd/scratch/hchen799/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/export/hdd/scratch/hchen799/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mreplicate\u001b[0;34m(self, module, device_ids)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/export/hdd/scratch/hchen799/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/replicate.py\u001b[0m in \u001b[0;36mreplicate\u001b[0;34m(network, devices, detach)\u001b[0m\n\u001b[1;32m    146\u001b[0m                     \u001b[0;31m# parameters in replicas are no longer leaves,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                     \u001b[0;31m# so setattr them as non-parameter attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                     \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplica\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m                     \u001b[0;31m# expose the parameter for DDP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                     \u001b[0mreplica\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_former_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/export/hdd/scratch/hchen799/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1315\u001b[0m                     \u001b[0mbuffers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m                     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__delattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    iter = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        iter = iter + 1\n",
    "        #progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                     #% (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    print('Loss: %.8f | Acc: %.8f%% (%d/%d)'% (train_loss/(iter * 128), 100.*correct/total, correct, total))\n",
    "    \n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    iter = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            iter = iter + 1\n",
    "            #progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                         #% (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    print('Loss: %.8f | Acc: %.8f%% (%d/%d)'% (test_loss/(iter * 100), 100.*correct/total, correct, total))\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt_recon1.pth')\n",
    "        best_acc = acc\n",
    "        \n",
    "for epoch in range(start_epoch, start_epoch+200):\n",
    "    #lr = adjust_learning_rate(epoch)\n",
    "    start_time = time.time()\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    end_time = time.time()\n",
    "    print(\"the time for one epoch is:\", end_time - start_time)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae6f9e1-91f5-458f-aa1e-6b8543ef8a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py39': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7196c11a25c7107eaaa031b47bd89369c329df93a53e3e6cc3a3271096580128"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
